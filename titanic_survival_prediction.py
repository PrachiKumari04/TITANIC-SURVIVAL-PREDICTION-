# -*- coding: utf-8 -*-
"""TITANIC SURVIVAL PREDICTION

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1-GuwlVvAy2xJrqV8dZl9Crz_lQdEZ_O2
"""





import pandas as pd
from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import SVC
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, roc_curve
import matplotlib.pyplot as plt
import seaborn as sns

# Load the Titanic dataset
df = pd.read_csv('/content/drive/MyDrive/Titanic-Dataset.csv')


# Exploratory Data Analysis (EDA)
print(df.head())
print(df.info())
print(df.describe())

# Histogram of ages
plt.hist(df['Age'].dropna(), bins=20)
plt.xlabel('Age')
plt.ylabel('Count')
plt.title('Distribution of Passenger Ages on Titanic')
plt.show()

# Bar chart of survival by gender
sns.countplot(x='Sex', hue='Survived', data=df)
plt.title('Survival Count by Gender')
plt.show()

# Handle Non-Numerical Columns for Correlation
numerical_df = df.select_dtypes(include=['number'])  # Select only numerical columns
corr = numerical_df.corr()
sns.heatmap(corr, annot=True)
plt.title('Correlation Heatmap of Numerical Features')
plt.show()

# Feature Engineering
df['FamilySize'] = df['SibSp'] + df['Parch'] + 1
df['AgeBin'] = pd.cut(df['Age'], bins=[0, 18, 30, 50, 80], labels=['Child', 'Young Adult', 'Adult', 'Senior'])
df['Title'] = df['Name'].str.extract(' ([A-Za-z]+)\.', expand=False)

# Preprocessing
df['Age'].fillna(df['Age'].median(), inplace=True)
df['Sex'] = df['Sex'].map({'female': 0, 'male': 1})
df['Embarked'].fillna(df['Embarked'].mode()[0], inplace=True)

# Convert ALL categorical features to numerical using one-hot encoding
df = pd.get_dummies(df, columns=['Embarked', 'AgeBin', 'Title'])

df = df.drop(['Name', 'Ticket', 'Cabin'], axis=1)

# Split the data (AFTER converting to numerical)
X = df.drop('Survived', axis=1)
y = df['Survived']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Model Training and Evaluation
models = {
    'Logistic Regression': LogisticRegression(max_iter=1000),
    'Decision Tree': DecisionTreeClassifier(),
    'Random Forest': RandomForestClassifier(),
    'Support Vector Machine': SVC(probability=True)
}

results = {}
for name, model in models.items():
    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)
    y_prob = model.predict_proba(X_test)[:, 1]

    accuracy = accuracy_score(y_test, y_pred)
    precision = precision_score(y_test, y_pred)
    recall = recall_score(y_test, y_pred)
    f1 = f1_score(y_test, y_pred)
    roc_auc = roc_auc_score(y_test, y_prob)

    results[name] = {
        'Accuracy': accuracy,
        'Precision': precision,
        'Recall': recall,
        'F1 Score': f1,
        'ROC AUC': roc_auc
    }

    print(f"{name} Results:")
    print(f"Accuracy: {accuracy:.4f}")
    print(f"Precision: {precision:.4f}")
    print(f"Recall: {recall:.4f}")
    print(f"F1 Score: {f1:.4f}")
    print(f"ROC AUC: {roc_auc:.4f}")
    print()

# ROC Curves
plt.figure(figsize=(10, 8))
for name, model in models.items():
    y_prob = model.predict_proba(X_test)[:, 1]
    fpr, tpr, _ = roc_curve(y_test, y_prob)
    plt.plot(fpr, tpr, label=f"{name} (AUC = {results[name]['ROC AUC']:.2f})")

plt.plot([0, 1], [0, 1], 'k--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC Curves')
plt.legend(loc='lower right')
plt.show()

# Model Performance Comparison
metrics_df = pd.DataFrame(results).T
metrics_df.plot(kind='bar', figsize=(12, 8))
plt.title('Model Performance Comparison')
plt.xlabel('Model')
plt.ylabel('Score')
plt.xticks(rotation=45)
plt.show()

# Feature Importance for Decision Tree and Random Forest
for name, model in models.items():
    if hasattr(model, 'feature_importances_'):
        feature_importances = pd.Series(model.feature_importances_, index=X.columns)
        feature_importances = feature_importances.nlargest(10)

        plt.figure(figsize=(10, 6))
        feature_importances.plot(kind='barh')
        plt.title(f'Top 10 Important Features for {name}')
        plt.xlabel('Feature Importance Score')
        plt.show()

# Hyperparameter Tuning (Example with Random Forest)
param_grid = {'n_estimators': [50, 100, 200], 'max_depth': [None, 5, 10]}
grid_search = GridSearchCV(estimator=models['Random Forest'], param_grid=param_grid, cv=5)
grid_search.fit(X_train, y_train)
print("Best Hyperparameters for Random Forest:", grid_search.best_params_)

# Cross-Validation (Example with Logistic Regression)
scores = cross_val_score(models['Logistic Regression'], X, y, cv=5)
print("Cross-validation scores for Logistic Regression:", scores)
print("Average cross-validation score:", scores.mean())